<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Resume</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 65em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
        max-width: 100%;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Resume</h1>
</header>
<div class="center">
<p><span><span class="smallcaps">Elias Oliver Chang</span></span><br />
Santa Clara, CA <span class="math inline">|</span> (818) 271-9829<br />
<a href="mailto:EMAIL">elochang@ucsc.edu</a> <span
class="math inline">|</span> <a
href="https://www.linkedin.com/in/oliver-chang-423a10171/"><u>linkedin.com/in/oliver-chang-423a10171</u></a>
<span class="math inline">|</span> <a
href="https://github.com/oliverc1623"><u>github.com/oliverc1623</u></a>
<span class="math inline">|</span> <a
href="https://runningonnumbers.com/about"><u>runningonnumbers.com</u></a></p>
</div>
<h1 id="education">Education</h1>
<ul>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>University of California Santa
Cruz</strong></td>
<td style="text-align: right;"><strong>Santa Cruz, CA</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Ph.D. &amp; M.S. Computer Science and
Engineering /4.00 GPA</td>
<td style="text-align: right;">09/2022 - 06/2027</td>
</tr>
</tbody>
</table>
<p><u>Relevant courses:</u> AI (graph search optimization), Deep
learning (TensorFlow / PyTorch, NumPy, Pandas, Matplotlib),<br />
Computer Architecture (RISC-V, Assembly), Compiler Design (PLY, Regex,
C<code>++</code>),<br />
Advanced Topics in NLP (HuggingFace, Transformers)</p></li>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Pomona College</strong></td>
<td style="text-align: right;"><strong>Claremont, CA</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">B.A. Computer Science &amp; Mathematics
/4.00 GPA</td>
<td style="text-align: right;">09/2018 - 05/2022</td>
</tr>
</tbody>
</table>
<p>Thesis: “Fast Matrix Multiplication: A Song of Mathematics and
Computer Science"</p></li>
</ul>
<h1 id="experience">Experience</h1>
<ul>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Graduate Student
Researcher</strong></td>
<td style="text-align: right;"><strong>Santa Cruz, CA</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">University of California Santa Cruz</td>
<td style="text-align: right;">09/2022 - Current</td>
</tr>
</tbody>
</table>
<ul>
<li><p><span> <span>Invented new transferable <strong>reinforcement
learning (RL)</strong> algorithm for <strong>continuous control
tasks</strong> using <strong>PyTorch</strong> and <strong>soft
actor-critic (SAC)</strong> which gained a <strong>67%</strong> increase
in rewards garnered against the baseline. </span> </span></p></li>
<li><p><span> <span>Vectorized algorithm using <strong>Torch Compile,
Torch RL, and CUDA Graphs</strong>, resulting in <span
class="math inline">5×</span> speed up in evaluating <strong>RL</strong>
algorithms across 500k timesteps. </span> </span></p></li>
<li><p><span> <span>Developed a novel <strong>SAC reward
function</strong> by using an <strong>MTL-robustness</strong>
formulation to train an adversarial RL agent, successfully finding
vulnerabilities in a <strong>2 dimensional</strong> search space instead
of <strong>1 dimension</strong>. </span> </span></p></li>
<li><p><span> <span>First-author paper to be submitted to <strong>AAAI
2026</strong>. </span> </span></p></li>
</ul></li>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>AI Program Coordinator
Intern</strong></td>
<td style="text-align: right;"><strong>San Jose, CA</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Lumentum</td>
<td style="text-align: right;">06/2024 - 09/2024</td>
</tr>
</tbody>
</table>
<ul>
<li><p><span> <span>Automated company-wide meeting summaries by
developing an <strong>Azure Function</strong> app that retrieves Teams
meeting transcripts via <strong>Microsoft Graph API</strong>, saving the
company 90 hours of manual labor. </span> </span></p></li>
<li><p><span> <span>Saved <strong>$250,000/year</strong> in liscensing
fees by implementing summarizer with <strong>OpenAI API (GPT-4o) and
<strong>Azure Function</strong></strong>, eliminating the need for
Microsoft Teams Premium for 4,500 employees. </span> </span></p></li>
<li><p><span> <span>Wrote <strong>Python</strong> code to <strong>Prompt
Engineer</strong> consistent summary generation, generate markdown, and
distribute email meeting organizers, resulting in a
<strong>bitbucket</strong> codebase that is used and maintained among 2
employee engineers. </span> </span></p></li>
<li><p><span> <span>Improved model training workflows by implementing
data integrity checks and handling compatibility with
<strong>DuckDB</strong>, <strong>AWS S3</strong>, and
<strong>PyTests</strong>, contributing to a <strong>CNN
(EfficientNetV2)</strong> model achieving an <strong>AUC of
0.97</strong>. </span> </span></p></li>
</ul></li>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Research Assistant</strong></td>
<td style="text-align: right;"><strong>Claremont, CA</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Pomona College</td>
<td style="text-align: right;">05/2021 - 07/2022</td>
</tr>
</tbody>
</table>
<ul>
<li><p><span> <span>Programmatically collected data for a custom dataset
by adding visual perturbations from a <strong>Normal
Distribution</strong>, increasing domain adaptation across
<strong>convolutional neural network (CNN)</strong> architectures by 7%.
</span> </span></p></li>
<li><p><span> <span>Visualized data results using
<strong>Seaborn</strong> and statistical tests using
<strong>Scikit-learn</strong>, revealing that <strong>Recurrent Neural
Networks (RNNs)</strong> outperformed <strong>ResNet</strong>
architectures by 9%. </span> </span></p></li>
<li><p><span> <span>First-author conference paper published at
<strong>IEEE Symposium on Computational Intelligence 2021</strong> <a
href="https://ieeexplore.ieee.org/document/9659907"><u>[LINK]</u>.</a>
</span> </span></p></li>
</ul></li>
</ul>
<h1 id="projects">Projects</h1>
<ul>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Collaborative Embodied Reasoning
in Autonomous Driving <a
href="https://github.com/oliverc1623/ceriad"><u>[LINK]</u></a></strong></td>
<td style="text-align: right;"><strong>09/2023-08/2024</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><p><span> <span>Improved autonomous vehicle decision-making in
<strong>CARLA</strong> by using <strong>LLMs (ChatGPT and
LLaMA)</strong> and <strong>LLaVA</strong> for embodied reasoning,
passing <strong>50</strong> more tests than baseline. </span>
</span></p></li>
<li><p><span> <span>Fine-tuned <strong>LLaVA</strong> image descriptions
by creating a dataset with 20,000 RGB-images, annotated with objects in
<strong>CARLA</strong>, resulting in shortened and specialized image
descriptions of driving scenes. </span> </span></p></li>
<li><p><span> <span>Made a <strong>Docker image</strong> and
<strong>Kubernetes</strong> deployment which is used by
<strong>6</strong> other lab members to run <strong>CARLA</strong> in a
remote server with a GUI desktop. </span> </span></p></li>
</ul></li>
<li><table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Foundation of Deep Learning Class
Final Project <a
href="https://github.com/oliverc1623/CSE244-Final-Project/blob/main/cse244-final-project.ipynb"><u>[LINK]</u></a></strong></td>
<td style="text-align: right;"><strong>09/2023-12/2023</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><p><span> <span>Scored a 72% image classification accuracy on a
custom dataset, which is composed of multiple datasets, by fine-tuning a
<strong>ResNet152</strong> in <strong>PyTorch</strong>, using
<strong>SGD</strong> and <strong>Cross Entropy Loss</strong>. </span>
</span></p></li>
<li><p><span> <span>Improved model performance by 15% by applying a
<strong>learning rate scheduler (Cosine Annealing)</strong>, a tailored
<strong>weighted sampling distribution</strong>, and <strong>image
augmentations</strong> such as <strong>resizing, transformations, and
random erasing</strong>. </span> </span></p></li>
<li><p><span> <span>Model placed in the <strong>75%</strong> percentile
in model accuracy among the entire class of 30 students in a
<strong>Kaggle competition</strong>. </span> </span></p></li>
</ul></li>
</ul>
<h1 id="publications">Publications</h1>
<ul>
<li><table>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><strong>Conferences/Workshops</strong></td>
<td style="text-align: right;"><strong></strong></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
</tr>
</tbody>
</table>
<ul>
<li><p><span> <span>Chang O., Kamat A. A., Self W. “Collaborative
Embodied Reasoning in Autonomous Driving". Training Agents with
Foundation Models workshop at RLC 2024 </span> </span></p></li>
<li><p><span> <span>Chang, O. “Solving Phase Ordering with Off-Policy
Deep Reinforcement Learning Algorithms". EuroLLVM 2024. Abstract
available at <a
href="https://llvm.swoogo.com/2024eurollvm/speakers"><u>[LINK]</u>.</a>
</span> </span></p></li>
<li><p><span> <span>Chang, O., Marchese, C., Mejia, J., and Clark, A.
(2021) “Investigating Neural Network Architectures, Techniques, and
Datasets for Autonomous Navigation" in Simulation" IEEE Symposium Series
on Computational Intelligence. <a
href="https://ieeexplore.ieee.org/document/9659907"><u>[LINK]</u></a>
</span> </span></p></li>
<li><p><span> <span>Chang, O., Gilpin, L. “Applying Policy Gradient
Methods to Image-Based Autonomous Vehicles". BayLearn 2023. Abstract
available at <a
href="https://github.com/oliverc1623/DRIVE-Sim/blob/main/baylearn-poster-github.pdf"><u>[LINK]</u>.</a>
</span> </span></p></li>
<li><p><span> <span>Chang, O. “Fast Matrix Multiplication: A Song of
Mathematics and Computer Science". Pomona College Mathematics Thesis
Presentation 2022. <a
href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://stephangarcia.sites.pomona.edu/misc/SRG-CurriculumVitae.pdf">[LINK]</a>
</span> </span></p></li>
<li><p><span> <span>Roberto C., Chang O., Gilpin H., La Rosa B.,
Proietti M., Ragno A. “eXplainable AI approaches for deep reinforcement
learning." AAAI 2024. Topics include but are not limited to XAI methods
for deep learning, evaluation of XAI methods, and self-explainable deep
reinforcement learning. <a
href="https://xai4drl.github.io/"><u>[LINK]</u>.</a> </span>
</span></p></li>
</ul></li>
</ul>
</body>
</html>
